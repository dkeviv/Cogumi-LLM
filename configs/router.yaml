# Router System Configuration (Phase 4)
# Intelligent routing between base model and specialized modifiers

# ============================================================================
# ROUTER MODEL (Phase 4A)
# ============================================================================
router:
  architecture: feedforward
  
  # Network Architecture
  layers:
    - input_dim: 128            # Feature vector size
      hidden_dims: [64, 32]     # Two hidden layers
      output_dim: 4             # Base, Code, Reasoning, Automation
      activation: relu
      dropout: 0.2
  
  # Feature Engineering
  features:
    confidence:
      - base_confidence         # Model's self-assessed confidence
      - token_perplexity        # Average perplexity of tokens
      - entropy                 # Prediction entropy
      
    query_analysis:
      - query_embedding         # Sentence-BERT embedding (384-dim → 128-dim PCA)
      - query_length            # Token count
      - has_code_markers        # Presence of ```, def, class, etc.
      - has_math_markers        # Presence of numbers, equations
      
    historical:
      - last_5_choices          # Session memory: last 5 routing decisions
      - last_5_successes        # Success rate of last 5 responses
  
  # Training Data Collection
  training_data:
    collection:
      script: src/phase4_router/collect_router_data.py
      num_queries: 35000
      collect: [confidence, correctness, features]
      output: data/phase4_router/training_35k.jsonl
      
    labeling:
      method: automatic          # Based on correctness
      labels:
        - use_base: Query answered correctly by base model
        - use_code: Query requires code modifier
        - use_reasoning: Query requires reasoning modifier
        - use_automation: Query requires automation modifier
  
  # Training Configuration
  training:
    optimizer: adam
    learning_rate: 0.001
    batch_size: 32
    epochs: 10
    early_stopping_patience: 3
    validation_split: 0.15      # 5,250 validation examples
    
  # Validation
  validation:
    test_size: 5000
    target_accuracy: 0.97       # 97% correct routing
    metrics:
      - accuracy
      - precision_per_class
      - recall_per_class
      - confusion_matrix
  
  # Output
  output:
    model_path: models/router_13mb
    size: 13MB
    accuracy: 97%
    inference_latency: <5ms     # On M4 Pro Mac

# ============================================================================
# ESCALATION DETECTOR (Phase 4B)
# ============================================================================
escalation:
  purpose: Detect user dissatisfaction and switch modifiers
  
  # Architecture
  base_model: bert-base-uncased
  task: binary_classification    # Satisfied vs Dissatisfied
  
  # Training Data
  training_data:
    sources:
      - dissatisfaction_phrases:  # "You don't understand", "That's wrong", etc.
          num_examples: 3000
          
      - negative_feedback:        # "Not helpful", "Try again", etc.
          num_examples: 2000
          
      - satisfied_responses:      # "Thank you", "Perfect", etc.
          num_examples: 1000
    
    total: 6000 examples
  
  # Training Configuration
  training:
    base: bert-base-uncased
    epochs: 3
    learning_rate: 2.0e-5
    batch_size: 16
    output: models/escalation_110mb
  
  # Knowledge Distillation
  distillation:
    teacher: models/escalation_110mb
    student_architecture: lstm  # Lightweight LSTM
    student_layers: 2
    student_hidden: 128
    compression_ratio: 36.7x    # 110MB → 3MB
    output: models/escalation_3mb
  
  # Validation
  validation:
    target_accuracy: 0.94       # 94% detection rate
    false_positive_rate: <0.06  # <6% false escalations
  
  # Output
  output:
    model_path: models/escalation_3mb
    size: 3MB
    accuracy: 94%
    inference_latency: <3ms

# ============================================================================
# CONFIDENCE THRESHOLDS (Phase 4C)
# ============================================================================
thresholds:
  # Default Mode (Balanced)
  default:
    base_threshold: 0.80        # Use base if confidence >80%
    expected_distribution:
      base: 45-55%
      code: 20-25%
      reasoning: 15-20%
      automation: 10-15%
  
  # Turbo Mode (Speed Priority)
  turbo:
    base_threshold: 0.85        # Prefer base for speed
    expected_distribution:
      base: 60-70%
      code: 15-20%
      reasoning: 10-15%
      automation: 5-10%
  
  # Max Quality Mode (Quality Priority)
  max_quality:
    base_threshold: 0.70        # Prefer modifiers for quality
    expected_distribution:
      base: 30-40%
      code: 25-30%
      reasoning: 20-25%
      automation: 15-20%
  
  # Optimization
  optimization:
    method: a_b_testing
    test_thresholds: [0.75, 0.80, 0.85]
    test_size: 5000
    metrics:
      - quality_score
      - response_latency
      - cost_per_query
    output: results/phase4c_optimal_threshold.json

# ============================================================================
# SESSION MEMORY
# ============================================================================
session:
  storage: sqlite
  database: data/sessions.db
  
  # Tracked Information
  tracking:
    - user_id: string
    - conversation_id: string
    - query_history: list[str]  # Last 10 queries
    - response_history: list[str]
    - routing_history: list[str]  # Which model was used
    - success_history: list[bool]  # Was response helpful?
    - escalation_count: int
  
  # Learning
  learning:
    update_frequency: every_query
    features:
      - successful_modifier_by_user  # Which modifier works for this user
      - topic_continuity              # Is conversation staying on topic?
      - escalation_trigger_patterns   # What causes dissatisfaction?
  
  # Privacy
  privacy:
    retention: 7 days           # Auto-delete after 7 days
    anonymize: true             # Hash user_id
    no_content_storage: true    # Store only metadata, not actual queries

# ============================================================================
# ROUTING FLOW
# ============================================================================
routing_flow:
  steps:
    1_receive_query:
      - Parse user input
      - Extract features
      - Load session history
    
    2_router_prediction:
      - Run router model
      - Get confidence scores for each target (base, code, reasoning, automation)
      - Consider session context
    
    3_threshold_check:
      - If base_confidence > threshold → Use base
      - Else → Select highest-scoring modifier
    
    4_load_model:
      - If base selected → Already loaded
      - If modifier selected → Load modifier (swap if different from last)
    
    5_generate_response:
      - Run selected model
      - Collect confidence scores
      - Generate response
    
    6_escalation_check:
      - User provides feedback (implicit or explicit)
      - Run escalation detector
      - If dissatisfaction detected → Switch to alternative modifier or escalate
    
    7_update_session:
      - Save routing decision
      - Save success/failure
      - Update session memory

# ============================================================================
# SYSTEM INTEGRATION
# ============================================================================
integration:
  models:
    base: models/phase2e_recovered_520mb
    modifiers:
      - models/phase3_code/code_modifier_47mb
      - models/phase3_reasoning/reasoning_modifier_48mb
      - models/phase3_automation/automation_modifier_40mb
    router: models/router_13mb
    escalation: models/escalation_3mb
  
  memory_management:
    base_always_loaded: true    # 520MB always in memory
    modifier_hot_swap: true     # Load only when needed
    max_memory: 568MB           # 520MB base + 48MB largest modifier
  
  performance:
    router_latency: <5ms
    escalation_latency: <3ms
    modifier_swap_time: <100ms  # Load from disk
    total_overhead: <108ms

# ============================================================================
# MONITORING & ANALYTICS
# ============================================================================
monitoring:
  metrics:
    routing:
      - distribution_per_mode: Percentage using each model
      - accuracy: Was routing decision correct?
      - latency: Time to make decision
      
    quality:
      - user_satisfaction: Implicit + explicit feedback
      - escalation_rate: Percentage of dissatisfied users
      - success_by_modifier: Which modifier performs best?
      
    cost:
      - queries_per_model: Track usage distribution
      - avg_cost_per_query: Base is cheap, modifiers slightly more expensive
      
  dashboard:
    platform: grafana
    refresh: real_time
    alerts:
      - routing_accuracy_drop: If <95%, investigate
      - escalation_spike: If >10%, check quality
      - cost_anomaly: If cost/query increases suddenly

# Total Cost: $75 (Router $45 + Escalation $30)
# Total Duration: 2 weeks
# Output Size: 16MB (Router 13MB + Escalation 3MB)
