# Copilot Instructions for Cogumi-LLM Project

## Code Quality Standards

### 1. Always Check Problems Panel After Editing

**CRITICAL**: After making ANY changes to code files, ALWAYS:

1. **Run the `get_errors` tool** to check for compile/type errors
2. **Fix all errors** before committing changes
3. **Re-run `get_errors`** to verify fixes

```
After editing: get_errors() ‚Üí Fix issues ‚Üí get_errors() again ‚Üí Commit
```

### 2. Types of Errors to Address

‚úÖ **MUST FIX**:
- Type annotation errors
- Syntax errors
- Import errors (for packages that should be available)
- Function signature mismatches
- Return type mismatches

‚ö†Ô∏è **CAN IGNORE** (Environment-Specific):
- Missing `google.colab` imports (when working locally)
- Missing `trl` or other training packages (when not in training environment)
- `!pip` vs `%pip` warnings in notebook cells (Colab-specific)
- CUDA/torch version warnings when not on GPU

### 3. Python Type Hints Best Practices

- Use `Optional[Type]` or `Type | None` for optional parameters
- For Python < 3.10, prefer `Optional[Type]` from `typing` module
- Always match function return type annotations with actual returns
- Example:
  ```python
  from typing import Optional, Dict, List
  
  def my_function(param: Optional[int] = None) -> Dict:
      # Returns a dict, not the annotated type
      return {"result": param}
  ```

### 4. Commit Workflow

Before every commit:
```bash
1. Make code changes
2. Run get_errors() tool
3. Fix any real errors (ignore environment-specific ones)
4. Run get_errors() again to verify
5. git add <files>
6. git commit -m "descriptive message"
7. git push
```

### 5. Notebook-Specific Rules

- **Colab notebooks** will have `!pip` commands - this is correct for Google Colab
- **Local notebooks** should use `%pip` if running in VS Code
- Import errors for `google.colab` are expected when editing locally
- Always test notebooks in their target environment (Colab vs Local)

### 6. Quick Error Check Command

For Python files:
```bash
get_errors(filePaths=["/path/to/file1.py", "/path/to/file2.py"])
```

For all files:
```bash
get_errors()
```

## Project-Specific Notes

### Training Pipeline
- Phase 1A uses Google Colab with A100 GPU
- Dependencies must be compatible: torch 2.4.0, transformers 4.41.0, peft 0.12.0
- Use native HuggingFace Trainer (not Axolotl)

### Dataset
- 640,637 examples, 99.46% English
- Located: `data/phase1/public_500k_filtered.jsonl`
- Compressed version: `public_500k_filtered.jsonl.gz` (264 MB)

### Common Fixes Applied

1. **verify_dataset.py**: Changed `sample_size: int = None` to `sample_size: Optional[int] = None`
2. **vocab_trimming.py**: Changed return type from `AutoTokenizer` to `Dict` to match actual return value

---

**Remember**: Clean code with no errors = fewer bugs = faster development! üöÄ
