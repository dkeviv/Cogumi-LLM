{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aff11eaa",
   "metadata": {},
   "source": [
    "# Cogumi-LLM Training on Google Colab Pro+\n",
    "\n",
    "## Overview\n",
    "This notebook trains the Qwen 2.5 7B model using QLoRA on Google Colab Pro+ A100 40GB GPU.\n",
    "\n",
    "**Training Details:**\n",
    "- Model: Qwen 2.5 7B (7.62B parameters)\n",
    "- Method: QLoRA 4-bit quantization\n",
    "- Dataset: 640,637 samples (870MB)\n",
    "- Expected Time: 20-25 hours\n",
    "- Compute Units: ~62.5 units\n",
    "\n",
    "**Prerequisites:**\n",
    "- ✅ Google Colab Pro+ subscription\n",
    "- ✅ Training data: `public_500k_filtered.jsonl` (870MB)\n",
    "- ✅ A100 GPU runtime selected\n",
    "\n",
    "## Instructions\n",
    "Run cells sequentially from top to bottom. Each cell has explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387348f",
   "metadata": {},
   "source": [
    "## Step 1: Verify GPU and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc1faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability and type\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"GPU Memory: {total_memory:.1f} GB\")\n",
    "    \n",
    "    # Verify we have A100 with enough memory\n",
    "    assert 'A100' in torch.cuda.get_device_name(0), \"Please select A100 GPU runtime\"\n",
    "    assert total_memory >= 35, f\"Insufficient GPU memory: {total_memory:.1f}GB < 35GB\"\n",
    "    \n",
    "    print(f\"\\n✅ Environment ready for training!\")\n",
    "else:\n",
    "    print(\"\\n❌ CUDA not available. Please select GPU runtime.\")\n",
    "    print(\"Go to: Runtime → Change runtime type → Select A100 GPU\")\n",
    "\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67c89d5",
   "metadata": {},
   "source": [
    "## Step 2: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eccf3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Clone the repository if not already cloned\n",
    "if not os.path.exists('Cogumi-LLM'):\n",
    "    print(\"Cloning Cogumi-LLM repository...\")\n",
    "    !git clone https://github.com/YOUR_USERNAME/Cogumi-LLM.git\n",
    "    print(\"✅ Repository cloned\")\n",
    "else:\n",
    "    print(\"✅ Repository already exists\")\n",
    "\n",
    "# Change to project directory\n",
    "%cd Cogumi-LLM\n",
    "\n",
    "# Show current status\n",
    "!pwd\n",
    "!git log --oneline -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de33ad2",
   "metadata": {},
   "source": [
    "## Step 3: Upload Training Data\n",
    "\n",
    "**Important**: Upload the `public_500k_filtered.jsonl` file (870MB) from your local machine.\n",
    "\n",
    "This will take 2-3 minutes depending on your internet speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc957f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Create directory structure\n",
    "!mkdir -p data/phase1\n",
    "\n",
    "# Check if file already exists\n",
    "data_file = 'data/phase1/public_500k_filtered.jsonl'\n",
    "\n",
    "if os.path.exists(data_file):\n",
    "    print(f\"✅ Training data already uploaded\")\n",
    "    !ls -lh {data_file}\n",
    "    !wc -l {data_file}\n",
    "else:\n",
    "    print(\"📤 Please upload: public_500k_filtered.jsonl (870MB)\")\n",
    "    print(\"This will take 2-3 minutes...\\n\")\n",
    "    \n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Move to correct location\n",
    "    for filename in uploaded.keys():\n",
    "        if filename.endswith('.jsonl'):\n",
    "            !mv {filename} {data_file}\n",
    "            print(f\"\\n✅ File uploaded successfully\")\n",
    "            break\n",
    "    \n",
    "    # Verify upload\n",
    "    print(\"\\nVerifying upload:\")\n",
    "    !ls -lh {data_file}\n",
    "    !wc -l {data_file}\n",
    "    \n",
    "    # Should show:\n",
    "    # -rw-r--r-- 1 root root 870M ... public_500k_filtered.jsonl\n",
    "    # 640637 data/phase1/public_500k_filtered.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a299f0a",
   "metadata": {},
   "source": [
    "## Step 4: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061efc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python packages\n",
    "print(\"Installing dependencies (3-5 minutes)...\\n\")\n",
    "\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q flash-attn --no-build-isolation\n",
    "\n",
    "print(\"\\n✅ Dependencies installed\")\n",
    "\n",
    "# Verify key packages\n",
    "import transformers\n",
    "import peft\n",
    "import bitsandbytes\n",
    "\n",
    "print(f\"\\nPackage versions:\")\n",
    "print(f\"  transformers: {transformers.__version__}\")\n",
    "print(f\"  peft: {peft.__version__}\")\n",
    "print(f\"  bitsandbytes: {bitsandbytes.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb358466",
   "metadata": {},
   "source": [
    "## Step 5: Validate Training Setup\n",
    "\n",
    "This runs a 1-step training test to catch any issues before the full 25-hour run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a197681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation (2-3 minutes)\n",
    "print(\"Running pre-training validation...\\n\")\n",
    "\n",
    "!python scripts/validate_training_setup.py\n",
    "\n",
    "# Should see:\n",
    "# ✅ Data loaded successfully\n",
    "# ✅ Model loaded successfully  \n",
    "# ✅ Training step completed\n",
    "# ✅ Validation PASSED\n",
    "\n",
    "print(\"\\n✅ Validation complete - ready to start training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4a617e",
   "metadata": {},
   "source": [
    "## Step 6: Start Training\n",
    "\n",
    "**⚠️ This will run for 20-25 hours**\n",
    "\n",
    "- Keep this browser tab open (can minimize)\n",
    "- Training will save checkpoints every 500 steps\n",
    "- Monitor progress in the output below\n",
    "\n",
    "**Expected behavior:**\n",
    "- Initial setup: 5-10 minutes (downloading model)\n",
    "- Training: ~1.5 hours per epoch × 15 epochs = 22.5 hours\n",
    "- Loss should decrease from ~2.5 to ~1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9f6635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"🚀 Training started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Expected completion: ~{25} hours from now\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python scripts/train_qwen_qlora.py\n",
    "\n",
    "# Training complete\n",
    "end_time = time.time()\n",
    "duration_hours = (end_time - start_time) / 3600\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"✅ Training completed!\")\n",
    "print(f\"Total time: {duration_hours:.2f} hours\")\n",
    "print(f\"Finished at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c536e480",
   "metadata": {},
   "source": [
    "## Step 7: Monitor Progress (Optional)\n",
    "\n",
    "Run this cell in parallel while training to monitor progress without interrupting the main training cell.\n",
    "\n",
    "**Note**: You need to run this in a separate browser tab pointing to the same notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee9f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor training logs\n",
    "!tail -f logs/training_*.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1073ec0",
   "metadata": {},
   "source": [
    "## Step 8: Check Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0101ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List saved checkpoints\n",
    "print(\"Saved checkpoints:\\n\")\n",
    "!ls -lth models/qwen-7b-qlora-phase2/ | head -20\n",
    "\n",
    "# Show model directory size\n",
    "!du -sh models/qwen-7b-qlora-phase2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da19fc5c",
   "metadata": {},
   "source": [
    "## Step 9: Keep Session Alive (Optional)\n",
    "\n",
    "Run this to prevent session timeout. Colab sessions can timeout after 12 hours of inactivity.\n",
    "\n",
    "**Note**: Stop this cell manually when training completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abd8335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"🔄 Session keep-alive started\")\n",
    "print(\"This will ping every 5 minutes to keep the session active.\")\n",
    "print(\"Stop this cell manually when done.\\n\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"✅ Session active at {current_time}\")\n",
    "        time.sleep(300)  # 5 minutes\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n🛑 Keep-alive stopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa13393",
   "metadata": {},
   "source": [
    "## Step 10: Download Trained Model\n",
    "\n",
    "After training completes, compress and download the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e4f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress the trained model\n",
    "print(\"Compressing model (this may take 5-10 minutes)...\\n\")\n",
    "\n",
    "!tar -czf qwen-7b-qlora-phase2.tar.gz models/qwen-7b-qlora-phase2/\n",
    "\n",
    "print(\"\\n✅ Model compressed\")\n",
    "!ls -lh qwen-7b-qlora-phase2.tar.gz\n",
    "\n",
    "# Download to local machine\n",
    "print(\"\\nStarting download...\")\n",
    "from google.colab import files\n",
    "files.download('qwen-7b-qlora-phase2.tar.gz')\n",
    "\n",
    "print(\"\\n✅ Download started - check your browser's download folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0abd857",
   "metadata": {},
   "source": [
    "## Resume Training from Checkpoint (If Needed)\n",
    "\n",
    "If your session disconnected, use this cell to resume from the last checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db40a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the latest checkpoint\n",
    "!ls -lt models/qwen-7b-qlora-phase2/ | grep checkpoint | head -1\n",
    "\n",
    "# Replace XXXX with the checkpoint number\n",
    "# checkpoint_num = \"XXXX\"  # e.g., \"1000\"\n",
    "# !python scripts/train_qwen_qlora.py --resume_from_checkpoint models/qwen-7b-qlora-phase2/checkpoint-{checkpoint_num}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f9a432",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Session Disconnected\n",
    "- Resume from last checkpoint (see cell above)\n",
    "- Checkpoints saved every 500 steps\n",
    "\n",
    "### CUDA Out of Memory\n",
    "- Shouldn't happen on A100 40GB\n",
    "- If it does, reduce batch size in `configs/student_model.yaml`\n",
    "\n",
    "### Training Too Slow\n",
    "- Check GPU utilization: `!nvidia-smi`\n",
    "- Should show ~90-95% GPU usage\n",
    "\n",
    "### Upload Failed\n",
    "- File too large for browser\n",
    "- Alternative: Host file on cloud and use `!wget`\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. ✅ Download trained model\n",
    "2. Evaluate on benchmarks\n",
    "3. Proceed to Phase 3a (general modifiers)\n",
    "4. Proceed to Phase 3b (coding modifiers)\n",
    "\n",
    "## Resources\n",
    "\n",
    "- Full Guide: `docs/COLAB_PRO_PLUS_GUIDE.md`\n",
    "- Training Config: `configs/student_model.yaml`\n",
    "- Execution Plan: `docs/EXECUTION_PLAN.md`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
