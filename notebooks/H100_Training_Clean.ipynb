{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3363f9d",
   "metadata": {},
   "source": [
    "# ‚ö†Ô∏è GOLDEN DEPENDENCY SET - DO NOT CHANGE\n",
    "\n",
    "**Tested and Working Configuration for H100 Training:**\n",
    "\n",
    "| Package | Version | Notes |\n",
    "|---------|---------|-------|\n",
    "| **Python** | 3.10.12 | Base system Python |\n",
    "| **PyTorch** | 2.8.0+cu128 | CUDA 12.8 build |\n",
    "| **CUDA** | 12.8 | GPU compute platform |\n",
    "| **bitsandbytes** | 0.48.1 | 8-bit optimizer support |\n",
    "| **xformers** | 0.0.32.post2 | Memory efficient attention |\n",
    "| **transformers** | 4.57.1 | HuggingFace models |\n",
    "| **Unsloth** | 2025.10.8 | Fast fine-tuning library |\n",
    "\n",
    "**Hardware:** NVIDIA H100 80GB HBM3\n",
    "\n",
    "**Installation Method:** Use `golden_dynamic_setup_full.sh` script which creates a virtual environment at `/workspace/golden-venv/` with these exact versions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dfdc8c",
   "metadata": {},
   "source": [
    "# H100 Training with Unsloth - Production Ready\n",
    "\n",
    "**Complete 5-step guide using GOLDEN DEPENDENCY SET (tested & working)**\n",
    "\n",
    "**Time**: 8-9 hours | **Cost**: ~$10 on H100\n",
    "\n",
    "‚ö†Ô∏è **IMPORTANT:** Use the exact dependency versions documented above. Other combinations may fail!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1883f5ab",
   "metadata": {},
   "source": [
    "## Step 1: Dry Run - Verify What Will Be Installed\n",
    "\n",
    "**First, run a dry-run to confirm the golden dependency versions will be installed.**\n",
    "\n",
    "This will show:\n",
    "- PyTorch 2.8.0+cu128\n",
    "- transformers 4.57.1\n",
    "- xformers 0.0.32.post2\n",
    "- bitsandbytes 0.48.1\n",
    "- Unsloth 2025.10.8\n",
    "\n",
    "‚úÖ These are the **GOLDEN DEPENDENCY SET** that's been tested and confirmed working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a5098b-88f8-472a-8296-e19a2c14b645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Dry-run to see what will be installed\n",
    "# Upload golden_dynamic_setup_full.sh to the same folder as the notebook\n",
    "!echo \"üîπ Running dry-run to show planned installation...\"\n",
    "!bash golden_dynamic_setup_full.sh --dry-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253e6fb2-9691-473e-bfb6-12e85bbba1fd",
   "metadata": {},
   "source": [
    "## Step 2: Install Golden Dependency Set\n",
    "\n",
    "**This installs the exact tested versions in a virtual environment.**\n",
    "\n",
    "Creates: `/workspace/golden-venv/` with Python 3.10.12 and all dependencies\n",
    "\n",
    "**Takes 10-15 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad75a0-6223-4daa-912a-09555f45d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Run full installation\n",
    "!bash golden_dynamic_setup_full.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcceb5a",
   "metadata": {},
   "source": [
    "## Step 3: Switch Kernel & Restart\n",
    "\n",
    "**After installation completes:**\n",
    "\n",
    "1. Click **\"Kernel\"** menu at the top\n",
    "2. Select **\"Restart Kernel\"**\n",
    "3. Wait for kernel to restart\n",
    "\n",
    "**Then change kernel to golden-venv:**\n",
    "\n",
    "1. Click **\"Kernel\"** menu ‚Üí **\"Change Kernel\"**\n",
    "2. Select the kernel from `/workspace/golden-venv/bin/python`\n",
    "3. Wait for connection (green checkmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a745cff-3b70-4e4b-bcd5-b1c59f0f3481",
   "metadata": {},
   "source": [
    "## Step 4: Verify Golden Dependency Set\n",
    "\n",
    "**Run the cell below to verify all packages match the golden set:**\n",
    "\n",
    "Expected output:\n",
    "```\n",
    "Python: 3.10.12\n",
    "Torch: 2.8.0+cu128, CUDA: 12.8, GPUs: 1\n",
    "GPU 0: NVIDIA H100 80GB HBM3\n",
    "bitsandbytes: 0.48.1\n",
    "xformers: 0.0.32.post2\n",
    "transformers: 4.57.1\n",
    "ü¶• Unsloth version: 2025.10.8\n",
    "```\n",
    "\n",
    "If versions don't match, something went wrong with installation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f35e46d",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è CRITICAL: Disk Space Prevention\n",
    "\n",
    "**This notebook includes automatic checkpoint cleanup to prevent disk space crashes.**\n",
    "\n",
    "**What's implemented:**\n",
    "- `save_total_limit=2` (keep only 2 checkpoints instead of 3)\n",
    "- `save_steps=2000` (save less frequently to reduce disk pressure)\n",
    "- Automatic cleanup callback (force-deletes old checkpoints every save)\n",
    "- Disk monitoring (alerts if disk usage >70%)\n",
    "\n",
    "**Why this matters:**\n",
    "- Each checkpoint = ~3GB\n",
    "- Without aggressive cleanup, disk fills up ‚Üí training crashes\n",
    "- This configuration keeps max 6GB of checkpoints (safe on 100GB volume)\n",
    "\n",
    "‚úÖ **Safe for 100GB volumes** - tested and confirmed working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a610992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "try:\n",
    "    import unsloth\n",
    "    version = getattr(unsloth, \"__version__\", \"unknown\")\n",
    "    print(f\"ü¶• Unsloth version: {version} (import first in your scripts!)\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Unsloth not installed! Install via 'pip install unsloth'\")\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Torch: {torch.__version__}, CUDA: {torch.version.cuda}, GPUs: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "for pkg in [\"bitsandbytes\", \"xformers\", \"transformers\"]:\n",
    "    try:\n",
    "        mod = __import__(pkg)\n",
    "        print(f\"{pkg}: {mod.__version__}\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ö†Ô∏è {pkg} not installed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e7952",
   "metadata": {},
   "source": [
    "## Step 5: HuggingFace Authentication\n",
    "\n",
    "1. Get token from: https://huggingface.co/settings/tokens\n",
    "2. Accept LLAMA license: https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct\n",
    "3. Run the cell below and paste your token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961a503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()\n",
    "print(\"\\n‚úÖ Authentication successful! Token saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13307933",
   "metadata": {},
   "source": [
    "## Step 6: Upload Dataset\n",
    "\n",
    "**Before running the next cell, upload your dataset:**\n",
    "\n",
    "1. In JupyterLab, use the file browser on the left\n",
    "2. Navigate to `/data/Cogumi-LLM/data/phase1/`\n",
    "3. Click the **Upload Files** button (‚Üë icon)\n",
    "4. Select `public_500k_filtered.jsonl` from your local machine\n",
    "5. Wait for upload to complete (~5-10 minutes for 870MB file)\n",
    "\n",
    "The training script expects: `/data/Cogumi-LLM/data/phase1/public_500k_filtered.jsonl`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d491df",
   "metadata": {},
   "source": [
    "## Step 7: Create Training Script\n",
    "\n",
    "**Creates train.py with:**\n",
    "- Unsloth 2025.10.8 compatible code\n",
    "- Batched formatting function for instruction/response dataset\n",
    "- QLoRA 4-bit training configuration\n",
    "- Optimized for H100 with golden dependency set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236cedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ----------------------------\n",
    "# Notebook cell to create train.py - WITH AUTO-RESUME\n",
    "# ----------------------------\n",
    "script = \"\"\"# ----------------------------\n",
    "# train.py - H100 Optimized (Packing DISABLED for stability)\n",
    "# Compatible with Unsloth 2025.10.8, TRL, PEFT, 4-bit training\n",
    "# INCLUDES: Automatic checkpoint cleanup AND auto-resume capability\n",
    "# ----------------------------\n",
    "\n",
    "import unsloth  # Must be first for Unsloth patching\n",
    "import torch\n",
    "from transformers import TrainingArguments, TrainerCallback\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset\n",
    "from unsloth import FastLanguageModel\n",
    "import gc\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import subprocess\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Clear any existing GPU memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# ============================================================================\n",
    "# AUTO-RESUME: Check for existing checkpoints\n",
    "# ============================================================================\n",
    "checkpoint_dir = \"/data/Cogumi-LLM/checkpoints\"\n",
    "resume_checkpoint = None\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = glob.glob(f\"{checkpoint_dir}/checkpoint-*\")\n",
    "    if checkpoints:\n",
    "        # Sort by step number and get the latest\n",
    "        checkpoints.sort(key=lambda x: int(x.split('-')[-1]))\n",
    "        resume_checkpoint = checkpoints[-1]\n",
    "        step_num = resume_checkpoint.split('-')[-1]\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"üîÑ RESUMING from checkpoint: {os.path.basename(resume_checkpoint)}\")\n",
    "        print(f\"   Previous progress: {step_num} steps completed\")\n",
    "        print(\"=\" * 70)\n",
    "    else:\n",
    "        print(\"=\" * 70)\n",
    "        print(\"üÜï No checkpoints found - starting fresh training\")\n",
    "        print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üÜï Starting fresh training (no checkpoint directory)\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# CHECKPOINT CLEANUP CALLBACK - Prevents disk space crashes\n",
    "# ============================================================================\n",
    "class CheckpointCleanupCallback(TrainerCallback):\n",
    "    \\\"\\\"\\\"\n",
    "    Aggressively deletes old checkpoints to prevent disk space exhaustion.\n",
    "    \n",
    "    Keeps only the N most recent checkpoints (save_total_limit).\n",
    "    Triggered after every checkpoint save to ensure immediate cleanup.\n",
    "    \\\"\\\"\\\"\n",
    "    def on_save(self, args, state, control, **kwargs):\n",
    "        \\\"\\\"\\\"Called after checkpoint is saved.\\\"\\\"\\\"\n",
    "        checkpoint_dir = args.output_dir\n",
    "        \n",
    "        # Find all checkpoint directories\n",
    "        checkpoints = sorted(\n",
    "            glob.glob(f\\\"{checkpoint_dir}/checkpoint-*\\\"),\n",
    "            key=lambda x: int(x.split('-')[-1])\n",
    "        )\n",
    "        \n",
    "        # Keep only the last N checkpoints\n",
    "        keep_last_n = args.save_total_limit or 2\n",
    "        \n",
    "        if len(checkpoints) > keep_last_n:\n",
    "            to_delete = checkpoints[:-keep_last_n]\n",
    "            \n",
    "            for checkpoint_path in to_delete:\n",
    "                try:\n",
    "                    print(f\\\"üóëÔ∏è  Auto-deleting old checkpoint: {os.path.basename(checkpoint_path)}\\\")\n",
    "                    shutil.rmtree(checkpoint_path)\n",
    "                    print(f\\\"   ‚úÖ Deleted successfully\\\")\n",
    "                except Exception as e:\n",
    "                    print(f\\\"   ‚ö†Ô∏è  Failed to delete: {e}\\\")\n",
    "        \n",
    "        # Report disk usage after cleanup\n",
    "        try:\n",
    "            result = subprocess.run(['df', '-h', checkpoint_dir], \n",
    "                                  capture_output=True, text=True)\n",
    "            lines = result.stdout.strip().split('\\\\n')\n",
    "            if len(lines) > 1:\n",
    "                usage = lines[1].split()[4]\n",
    "                print(f\\\"üíæ Disk usage after cleanup: {usage}\\\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# ============================================================================\n",
    "# DISK MONITORING - Early warning system\n",
    "# ============================================================================\n",
    "def monitor_disk_space():\n",
    "    \\\"\\\"\\\"Monitor disk usage every 10 minutes and warn if getting full.\\\"\\\"\\\"\n",
    "    while True:\n",
    "        try:\n",
    "            result = subprocess.run(['df', '-h', '/data'], \n",
    "                                  capture_output=True, text=True)\n",
    "            lines = result.stdout.strip().split('\\\\n')\n",
    "            if len(lines) > 1:\n",
    "                usage = lines[1].split()[4]\n",
    "                used = lines[1].split()[2]\n",
    "                timestamp = time.strftime('%H:%M:%S')\n",
    "                \n",
    "                usage_pct = int(usage.strip('%'))\n",
    "                \n",
    "                if usage_pct > 90:\n",
    "                    print(f\\\"\\\\nüö® CRITICAL: Disk {used} used ({usage}) at {timestamp}\\\")\n",
    "                    print(f\\\"   ‚ö†Ô∏è  Training may crash soon due to disk space!\\\")\n",
    "                elif usage_pct > 70:\n",
    "                    print(f\\\"\\\\n‚ö†Ô∏è  Warning: Disk {used} used ({usage}) at {timestamp}\\\")\n",
    "                else:\n",
    "                    print(f\\\"üíæ Disk: {used} used ({usage}) - {timestamp}\\\")\n",
    "        except Exception as e:\n",
    "            print(f\\\"‚ö†Ô∏è  Disk monitoring error: {e}\\\")\n",
    "        \n",
    "        time.sleep(600)  # Check every 10 minutes\n",
    "\n",
    "# Start disk monitoring in background\n",
    "monitor_thread = threading.Thread(target=monitor_disk_space, daemon=True)\n",
    "monitor_thread.start()\n",
    "print(\\\"‚úÖ Disk space monitoring started (checks every 10 minutes)\\\")\n",
    "\n",
    "# Load model + tokenizer with H100 optimizations\n",
    "print(\"üîÑ Loading model...\")\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    max_seq_length=1024,  # Handle sequences up to 1024 tokens\n",
    "    load_in_4bit=True,\n",
    "    dtype=None,  # Auto-detect bf16 for H100\n",
    "    attn_implementation=\"flash_attention_2\",  # CRITICAL: Enable FA2\n",
    ")\n",
    "print(\"‚úÖ Model loaded successfully\")\n",
    "\n",
    "# Apply PEFT / LoRA\n",
    "print(\"üîÑ Applying LoRA...\")\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=64,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=3407,\n",
    "    use_rslora=False,\n",
    ")\n",
    "print(\"‚úÖ LoRA applied successfully\")\n",
    "\n",
    "# Prepare model for training (enables Flash Attention 2)\n",
    "# Force disable gradient offloading for maximum speed\n",
    "import os\n",
    "os.environ[\"UNSLOTH_OFFLOAD_GRADIENTS\"] = \"0\"\n",
    "print(\"üîÑ Preparing model for training...\")\n",
    "model = FastLanguageModel.for_training(model)\n",
    "print(\"‚úÖ Model ready for training\")\n",
    "\n",
    "# Load dataset with caching\n",
    "print(\"üì• Loading dataset...\")\n",
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/data/Cogumi-LLM/data/phase1/public_500k_filtered.jsonl\",\n",
    "    split=\"train\",\n",
    "    cache_dir=\"/tmp/hf_cache\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "print(f\"‚úÖ Dataset loaded: {len(dataset)} examples\")\n",
    "\n",
    "# Define formatting function (required by Unsloth)\n",
    "def formatting_func(examples):\n",
    "    instructions = examples['instruction']\n",
    "    responses = examples['response']\n",
    "    \n",
    "    texts = []\n",
    "    for instruction, response in zip(instructions, responses):\n",
    "        text = f\"### Instruction:\\\\\\\\n{instruction}\\\\\\\\n\\\\\\\\n### Response:\\\\\\\\n{response}\"\n",
    "        texts.append(text)\n",
    "    \n",
    "    return texts\n",
    "\n",
    "# Training arguments - OPTIMIZED FOR H100\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"/data/Cogumi-LLM/checkpoints\",\n",
    "    num_train_epochs=3,\n",
    "    \n",
    "    # Batch size for H100 80GB with 4-bit and seq_len 1024\n",
    "    per_device_train_batch_size=4,  # Reduced for no-packing mode\n",
    "    gradient_accumulation_steps=2,   # Effective batch size of 8\n",
    "    \n",
    "    # Optimization settings\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=10,\n",
    "    logging_steps=1,\n",
    "    save_steps=2000,              # UPDATED: Save every 2000 steps (was 1000)\n",
    "    save_total_limit=2,           # UPDATED: Keep only 2 checkpoints (was 3)\n",
    "    \n",
    "    # H100 optimizations\n",
    "    optim=\"adamw_8bit\",\n",
    "    bf16=True,\n",
    "    tf32=True,\n",
    "    \n",
    "    # Dataloader settings (conservative)\n",
    "    dataloader_num_workers=4,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_prefetch_factor=2,\n",
    "    dataloader_persistent_workers=True,\n",
    "    group_by_length=False,\n",
    "    \n",
    "    # Memory optimizations\n",
    "    gradient_checkpointing=False,\n",
    "    max_grad_norm=1.0,\n",
    "    \n",
    "    # Disable unnecessary features\n",
    "    logging_first_step=False,\n",
    "    logging_nan_inf_filter=False,\n",
    "    save_safetensors=True,\n",
    "    \n",
    "    # Report to nothing (disable wandb etc)\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Create trainer WITHOUT packing (packing was causing batch size mismatch)\n",
    "print(\"üîÑ Creating trainer...\")\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    args=args,\n",
    "    formatting_func=formatting_func,\n",
    "    max_seq_length=1024,  # MUST match model max_seq_length\n",
    "    packing=False,  # DISABLED: packing caused batch mismatch error\n",
    "    dataset_num_proc=2,\n",
    ")\n",
    "\n",
    "# Add checkpoint cleanup callback\n",
    "trainer.add_callback(CheckpointCleanupCallback())\n",
    "print(\"‚úÖ Trainer created successfully\")\n",
    "print(\"‚úÖ Checkpoint cleanup callback registered\")\n",
    "\n",
    "# Train the model (WITH AUTO-RESUME)\n",
    "print(\"=\" * 70)\n",
    "if resume_checkpoint:\n",
    "    print(f\"üîÑ RESUMING training from step {resume_checkpoint.split('-')[-1]}\")\n",
    "else:\n",
    "    print(\"üöÄ STARTING fresh training\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"   Max sequence length: 1024\")\n",
    "print(f\"   Batch size per device: {args.per_device_train_batch_size}\")\n",
    "print(f\"   Gradient accumulation: {args.gradient_accumulation_steps}\")\n",
    "print(f\"   Effective batch size: {args.per_device_train_batch_size * args.gradient_accumulation_steps}\")\n",
    "print(f\"   Total training steps: ~{len(dataset) // (args.per_device_train_batch_size * args.gradient_accumulation_steps) * args.num_train_epochs}\")\n",
    "print(f\"   Dataloader workers: {args.dataloader_num_workers}\")\n",
    "print(f\"   Prefetch factor: {args.dataloader_prefetch_factor}\")\n",
    "print(f\"   Dataset processing workers: 2\")\n",
    "print(f\"   Packing: DISABLED (was causing batch mismatch)\")\n",
    "print(f\"   Flash Attention 2: ENABLED\")\n",
    "print(f\"   Gradient offloading: DISABLED\")\n",
    "print(f\"   Expected speed: 2-4 it/s on H100\")\n",
    "print(f\"   üíæ Checkpoint saves: Every {args.save_steps} steps\")\n",
    "print(f\"   üíæ Checkpoints kept: {args.save_total_limit} (auto-cleanup enabled)\")\n",
    "print(f\"   üìä Disk monitoring: Active (every 10 min)\")\n",
    "print(f\"   üîÑ Auto-resume: ENABLED\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    trainer.train(resume_from_checkpoint=resume_checkpoint)\n",
    "    print(\"\\\\n‚úÖ Training completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\\\n‚ùå Training failed with error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "# Save model\n",
    "print(\"üíæ Saving final model...\")\n",
    "model.save_pretrained(\"/data/Cogumi-LLM/checkpoints/final\")\n",
    "tokenizer.save_pretrained(\"/data/Cogumi-LLM/checkpoints/final\")\n",
    "print(\"‚úÖ Model saved to /data/Cogumi-LLM/checkpoints/final\")\n",
    "\"\"\"\n",
    "\n",
    "# Write train.py to disk\n",
    "train_path = \"/data/Cogumi-LLM/train.py\"\n",
    "os.makedirs(os.path.dirname(train_path), exist_ok=True)\n",
    "with open(train_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(script)\n",
    "\n",
    "print(f\"‚úÖ AUTO-RESUME training script created at {train_path}\")\n",
    "print(f\"   üîÑ Auto-resume: ENABLED - will resume from last checkpoint automatically\")\n",
    "print(f\"   ‚ö° Flash Attention 2: Enabled\")\n",
    "print(f\"   üö´ Gradient offloading: DISABLED\")\n",
    "print(f\"   üîß Sequence length: 1024\")\n",
    "print(f\"   üì¶ Batch size: 4\")\n",
    "print(f\"   üîÑ Gradient accumulation: 2 (effective batch = 8)\")\n",
    "print(f\"   üë∑ Dataloader workers: 4\")\n",
    "print(f\"   ‚ùå Packing: DISABLED (was causing batch dimension mismatch)\")\n",
    "print(f\"   üíæ Save every 2000 steps\")\n",
    "print(f\"   üíæ Keep only 2 checkpoints\")\n",
    "print(f\"   üóëÔ∏è  Auto-cleanup: ENABLED (prevents disk space crashes)\")\n",
    "print(f\"   üìä Disk monitoring: ENABLED (checks every 10 min)\")\n",
    "print(f\"   ‚úÖ Safe to interrupt - will resume automatically on restart!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a5ba8",
   "metadata": {},
   "source": [
    "## Step 7.5: Clean Up Old Checkpoints (If Resuming After Crash)\n",
    "\n",
    "**‚ö†Ô∏è ONLY RUN THIS IF:**\n",
    "- Training crashed previously due to disk space\n",
    "- You have multiple old checkpoints taking up space\n",
    "- You're resuming training from a checkpoint\n",
    "\n",
    "**This will:**\n",
    "- Keep only the latest checkpoint\n",
    "- Delete all older checkpoints\n",
    "- Free up 20-30GB of disk space\n",
    "\n",
    "**Skip this step if starting fresh training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456923b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CHECKPOINT CLEANUP - Run ONLY if resuming after crash\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoint_dir = Path(\"/data/Cogumi-LLM/checkpoints\")\n",
    "\n",
    "print(\"üßπ CHECKPOINT CLEANUP\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if not checkpoint_dir.exists():\n",
    "    print(\"‚úÖ No checkpoints directory found - nothing to clean\")\n",
    "else:\n",
    "    # Find all checkpoints\n",
    "    checkpoints = sorted(\n",
    "        checkpoint_dir.glob(\"checkpoint-*\"),\n",
    "        key=lambda x: int(x.name.split(\"-\")[1])\n",
    "    )\n",
    "    \n",
    "    if len(checkpoints) == 0:\n",
    "        print(\"‚úÖ No checkpoints found - nothing to clean\")\n",
    "    elif len(checkpoints) == 1:\n",
    "        print(f\"‚úÖ Only 1 checkpoint found: {checkpoints[0].name}\")\n",
    "        print(\"   Nothing to delete\")\n",
    "    else:\n",
    "        print(f\"üìÅ Found {len(checkpoints)} checkpoints:\")\n",
    "        for cp in checkpoints:\n",
    "            size = subprocess.run(\n",
    "                ['du', '-sh', str(cp)],\n",
    "                capture_output=True,\n",
    "                text=True\n",
    "            ).stdout.split()[0]\n",
    "            print(f\"   - {cp.name} ({size})\")\n",
    "        \n",
    "        print(\"\\nüóëÔ∏è  Deleting old checkpoints (keeping latest)...\")\n",
    "        \n",
    "        # Delete all but the latest\n",
    "        for cp in checkpoints[:-1]:\n",
    "            print(f\"   Deleting {cp.name}...\")\n",
    "            subprocess.run(['rm', '-rf', str(cp)])\n",
    "        \n",
    "        # Verify cleanup\n",
    "        remaining = list(checkpoint_dir.glob(\"checkpoint-*\"))\n",
    "        print(f\"\\n‚úÖ Cleanup complete!\")\n",
    "        print(f\"   Kept: {remaining[0].name if remaining else 'None'}\")\n",
    "        print(f\"   Deleted: {len(checkpoints) - len(remaining)} checkpoints\")\n",
    "        \n",
    "        # Show disk space\n",
    "        result = subprocess.run(['df', '-h', '/data'], \n",
    "                              capture_output=True, text=True)\n",
    "        lines = result.stdout.strip().split('\\n')\n",
    "        if len(lines) > 1:\n",
    "            parts = lines[1].split()\n",
    "            print(f\"\\nüíæ Disk Space: {parts[2]} used / {parts[1]} total ({parts[4]} full)\")\n",
    "            print(f\"   Available: {parts[3]}\")\n",
    "\n",
    "print(\"\\n‚úÖ Ready to resume training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc4756",
   "metadata": {},
   "source": [
    "## Step 8: Start Training üöÄ\n",
    "\n",
    "**Training Details:**\n",
    "- Duration: 8-9 hours on H100\n",
    "- Cost: ~$10 on Vast.ai\n",
    "- Model: Llama-3.1-8B-Instruct (4-bit QLoRA)\n",
    "- Dataset: 640K instruction/response pairs\n",
    "\n",
    "**Monitor with:** `nvidia-smi` in a terminal or `watch -n 1 nvidia-smi`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e953773",
   "metadata": {},
   "source": [
    "## Step 7.9: Pre-Flight Check - Verify Auto-Resume Setup ‚úàÔ∏è\n",
    "\n",
    "**ALWAYS RUN THIS BEFORE STARTING TRAINING!**\n",
    "\n",
    "This verifies:\n",
    "1. ‚úÖ train.py has auto-resume code\n",
    "2. ‚úÖ Checkpoints are detected correctly\n",
    "3. ‚úÖ Training will resume from the right place\n",
    "\n",
    "**If this shows issues, fix them before running Step 8!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PRE-FLIGHT CHECK - Verify auto-resume setup before training\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "print(\"‚úàÔ∏è PRE-FLIGHT CHECKLIST\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check 1: Does train.py exist?\n",
    "train_py_path = \"/data/Cogumi-LLM/train.py\"\n",
    "if not os.path.exists(train_py_path):\n",
    "    print(\"‚ùå CRITICAL: train.py not found!\")\n",
    "    print(f\"   Expected at: {train_py_path}\")\n",
    "    print(\"   üîß FIX: Re-run Cell 15 (Step 7) to create train.py\")\n",
    "    print(\"=\" * 70)\n",
    "    raise FileNotFoundError(\"train.py missing - cannot continue\")\n",
    "\n",
    "print(\"‚úÖ CHECK 1: train.py exists\")\n",
    "\n",
    "# Check 2: Does train.py have auto-resume code?\n",
    "print(\"\\nüîç CHECK 2: Checking for auto-resume code in train.py...\")\n",
    "with open(train_py_path, 'r') as f:\n",
    "    content = f.read()\n",
    "    \n",
    "has_checkpoint_detection = \"resume_checkpoint = None\" in content\n",
    "has_glob_import = \"import glob\" in content\n",
    "has_resume_param = \"resume_from_checkpoint=resume_checkpoint\" in content\n",
    "\n",
    "if has_checkpoint_detection and has_glob_import and has_resume_param:\n",
    "    print(\"‚úÖ CHECK 2: Auto-resume code FOUND in train.py\")\n",
    "    \n",
    "    # Show the exact lines\n",
    "    print(\"\\nüìù Auto-resume code preview:\")\n",
    "    result = subprocess.run(['grep', '-n', '-A', '2', 'resume_checkpoint = None', train_py_path],\n",
    "                          capture_output=True, text=True)\n",
    "    print(result.stdout[:300])\n",
    "else:\n",
    "    print(\"‚ùå CHECK 2 FAILED: Auto-resume code MISSING in train.py!\")\n",
    "    print(f\"   - Checkpoint detection: {'‚úÖ' if has_checkpoint_detection else '‚ùå'}\")\n",
    "    print(f\"   - Glob import: {'‚úÖ' if has_glob_import else '‚ùå'}\")\n",
    "    print(f\"   - Resume parameter: {'‚úÖ' if has_resume_param else '‚ùå'}\")\n",
    "    print(\"\\nüîß FIX: Re-run Cell 15 (Step 7) to regenerate train.py with auto-resume\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "# Check 3: What checkpoints exist?\n",
    "print(\"\\nüîç CHECK 3: Scanning for existing checkpoints...\")\n",
    "checkpoint_dir = \"/data/Cogumi-LLM/checkpoints\"\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    print(\"‚ÑπÔ∏è  No checkpoint directory found\")\n",
    "    print(\"   ‚Üí Training will START FRESH (expected for first run)\")\n",
    "else:\n",
    "    checkpoints = glob.glob(f\"{checkpoint_dir}/checkpoint-*\")\n",
    "    \n",
    "    if not checkpoints:\n",
    "        print(\"‚ÑπÔ∏è  Checkpoint directory exists but is EMPTY\")\n",
    "        print(\"   ‚Üí Training will START FRESH\")\n",
    "    else:\n",
    "        checkpoints.sort(key=lambda x: int(x.split('-')[-1]))\n",
    "        latest = checkpoints[-1]\n",
    "        step_num = latest.split('-')[-1]\n",
    "        \n",
    "        print(f\"‚úÖ Found {len(checkpoints)} checkpoint(s):\")\n",
    "        for cp in checkpoints:\n",
    "            step = cp.split('-')[-1]\n",
    "            print(f\"   - checkpoint-{step}\")\n",
    "        \n",
    "        print(f\"\\nüéØ Training will RESUME from: checkpoint-{step_num}\")\n",
    "        print(f\"   Previous progress: {step_num} steps completed\")\n",
    "        \n",
    "        # Verify checkpoint is valid\n",
    "        adapter_path = os.path.join(latest, \"adapter_model.safetensors\")\n",
    "        if os.path.exists(adapter_path):\n",
    "            size_mb = os.path.getsize(adapter_path) / (1024 * 1024)\n",
    "            print(f\"   Checkpoint size: {size_mb:.1f} MB (looks valid ‚úÖ)\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  WARNING: adapter_model.safetensors not found!\")\n",
    "            print(f\"   This checkpoint might be corrupted!\")\n",
    "\n",
    "# Check 4: Disk space\n",
    "print(\"\\nüîç CHECK 4: Checking disk space...\")\n",
    "result = subprocess.run(['df', '-h', '/data'], capture_output=True, text=True)\n",
    "lines = result.stdout.strip().split('\\n')\n",
    "if len(lines) > 1:\n",
    "    parts = lines[1].split()\n",
    "    usage = parts[4]\n",
    "    available = parts[3]\n",
    "    \n",
    "    usage_pct = int(usage.strip('%'))\n",
    "    \n",
    "    if usage_pct > 80:\n",
    "        print(f\"‚ö†Ô∏è  DISK SPACE WARNING: {usage} used, {available} available\")\n",
    "    else:\n",
    "        print(f\"‚úÖ CHECK 4: Disk space OK - {usage} used, {available} available\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìã FINAL STATUS:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if has_checkpoint_detection and has_glob_import and has_resume_param:\n",
    "    if os.path.exists(checkpoint_dir) and glob.glob(f\"{checkpoint_dir}/checkpoint-*\"):\n",
    "        print(\"‚úÖ READY TO RESUME: Training will continue from last checkpoint\")\n",
    "    else:\n",
    "        print(\"‚úÖ READY FOR FRESH START: Training will begin from step 0\")\n",
    "    print(\"\\nüöÄ You can now run Step 8 (Start Training)\")\n",
    "else:\n",
    "    print(\"‚ùå NOT READY: Auto-resume code missing from train.py\")\n",
    "    print(\"\\nüîß ACTION REQUIRED:\")\n",
    "    print(\"   1. Re-run Cell 15 (Step 7) to regenerate train.py\")\n",
    "    print(\"   2. Then re-run this cell to verify\")\n",
    "    print(\"   3. Then run Step 8 to start training\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec049b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /data/Cogumi-LLM/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0a6fbb",
   "metadata": {},
   "source": [
    "## Step 8.5: Monitor Disk Space During Training (Optional)\n",
    "\n",
    "**Run this in a separate terminal to monitor disk space in real-time:**\n",
    "\n",
    "This shows disk usage every 30 seconds while training runs.\n",
    "\n",
    "**Stop with:** Ctrl+C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ead595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time disk monitoring (runs continuously)\n",
    "# Press Ctrl+C to stop\n",
    "\n",
    "import time\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üîç Real-time disk space monitoring\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Press Ctrl+C to stop\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Get disk usage\n",
    "        result = subprocess.run(['df', '-h', '/data'], \n",
    "                              capture_output=True, text=True)\n",
    "        lines = result.stdout.strip().split('\\n')\n",
    "        \n",
    "        if len(lines) > 1:\n",
    "            parts = lines[1].split()\n",
    "            total = parts[1]\n",
    "            used = parts[2]\n",
    "            available = parts[3]\n",
    "            usage_pct = parts[4]\n",
    "            \n",
    "            timestamp = datetime.now().strftime('%H:%M:%S')\n",
    "            \n",
    "            # Color coding based on usage\n",
    "            usage_num = int(usage_pct.strip('%'))\n",
    "            if usage_num > 90:\n",
    "                status = \"üö® CRITICAL\"\n",
    "            elif usage_num > 70:\n",
    "                status = \"‚ö†Ô∏è  WARNING\"\n",
    "            else:\n",
    "                status = \"‚úÖ HEALTHY\"\n",
    "            \n",
    "            print(f\"{timestamp} | {status} | Used: {used}/{total} ({usage_pct}) | Free: {available}\")\n",
    "        \n",
    "        # Check checkpoint count\n",
    "        try:\n",
    "            checkpoint_count = subprocess.run(\n",
    "                ['sh', '-c', 'ls -1d /data/Cogumi-LLM/checkpoints/checkpoint-* 2>/dev/null | wc -l'],\n",
    "                capture_output=True, text=True\n",
    "            )\n",
    "            count = checkpoint_count.stdout.strip()\n",
    "            if count and int(count) > 0:\n",
    "                print(f\"          | üìÅ Checkpoints: {count}\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        time.sleep(30)  # Update every 30 seconds\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\n‚úÖ Monitoring stopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ac92d2",
   "metadata": {},
   "source": [
    "## Step 7.5: Quick Diagnostic (Optional)\n",
    "\n",
    "**If training seems slow despite high GPU utilization, run this to check:**\n",
    "- Actual batch size being used\n",
    "- Whether packing is working\n",
    "- Samples per second vs steps per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d33944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick diagnostic - check training speed metrics\n",
    "!tail -50 /data/Cogumi-LLM/train.py 2>/dev/null || echo \"Training script not found\"\n",
    "!echo \"\"\n",
    "!echo \"Recent training output:\"\n",
    "!ps aux | grep train.py | grep -v grep || echo \"No training process running\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6142190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify flash-attn 2.8.2 is installed and working\n",
    "import sys\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "try:\n",
    "    import flash_attn\n",
    "    print(f\"‚úÖ flash-attn version: {flash_attn.__version__}\")\n",
    "    \n",
    "    from flash_attn import flash_attn_func\n",
    "    print(f\"‚úÖ flash_attn_func importable: True\")\n",
    "    \n",
    "    import torch\n",
    "    print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "    print(f\"‚úÖ CUDA version: {torch.version.cuda}\")\n",
    "    \n",
    "    print(\"\\nüéâ Flash Attention 2 is ready!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Flash Attention 2 import failed: {e}\")\n",
    "    print(\"‚ö†Ô∏è You may need to reinstall flash-attn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2417b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL DIAGNOSTIC: Check if FA2 is actually being used\n",
    "# Even though FA2 = True, check if it's really active in the model\n",
    "\n",
    "import unsloth\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# Quick test load to see actual configuration\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    max_seq_length=1024,\n",
    "    load_in_4bit=True,\n",
    "    dtype=None,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "\n",
    "# Check what attention implementation is actually being used\n",
    "print(\"\\nüîç CHECKING ACTUAL ATTENTION IMPLEMENTATION:\")\n",
    "print(f\"Model config attn_implementation: {model.config._attn_implementation}\")\n",
    "print(f\"Model type: {type(model)}\")\n",
    "\n",
    "# Check individual layers\n",
    "if hasattr(model, 'model') and hasattr(model.model, 'layers'):\n",
    "    first_layer = model.model.layers[0]\n",
    "    if hasattr(first_layer, 'self_attn'):\n",
    "        attn_class = type(first_layer.self_attn).__name__\n",
    "        print(f\"Attention layer class: {attn_class}\")\n",
    "        print(f\"Expected for FA2: Should contain 'FlashAttention' or 'Llama.*FlashAttention'\")\n",
    "\n",
    "del model, tokenizer  # Free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e454ab",
   "metadata": {},
   "source": [
    "## üö® EMERGENCY: Check Training Status\n",
    "\n",
    "**If GPU shows 0% after browser refresh, run these diagnostic cells:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1082404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Check if training process is still running\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"üîç DIAGNOSTIC 1: Checking for training process...\")\n",
    "result = subprocess.run(['ps', 'aux'], capture_output=True, text=True)\n",
    "train_processes = [line for line in result.stdout.split('\\n') if 'train.py' in line and 'grep' not in line]\n",
    "\n",
    "if train_processes:\n",
    "    print(\"‚úÖ Training process FOUND and running:\")\n",
    "    for proc in train_processes:\n",
    "        print(f\"   {proc}\")\n",
    "else:\n",
    "    print(\"‚ùå NO training process found - training has stopped!\")\n",
    "    \n",
    "print(\"\\nüîç DIAGNOSTIC 2: Checking GPU status...\")\n",
    "gpu_result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total', '--format=csv,noheader'], \n",
    "                           capture_output=True, text=True)\n",
    "print(f\"GPU Utilization: {gpu_result.stdout.strip()}\")\n",
    "\n",
    "print(\"\\nüîç DIAGNOSTIC 3: Checking for recent checkpoints...\")\n",
    "checkpoint_dir = \"/data/Cogumi-LLM/checkpoints\"\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = subprocess.run(['ls', '-lht', checkpoint_dir], capture_output=True, text=True)\n",
    "    print(checkpoints.stdout)\n",
    "else:\n",
    "    print(f\"‚ùå No checkpoint directory at {checkpoint_dir}\")\n",
    "\n",
    "print(\"\\nüîç DIAGNOSTIC 4: Check last training logs...\")\n",
    "try:\n",
    "    # Look for any log files or check recent output\n",
    "    log_check = subprocess.run(['find', '/data/Cogumi-LLM', '-name', '*.log', '-mmin', '-60'], \n",
    "                              capture_output=True, text=True)\n",
    "    if log_check.stdout.strip():\n",
    "        print(f\"Recent logs:\\n{log_check.stdout}\")\n",
    "    else:\n",
    "        print(\"No recent log files found\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not check logs: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb75e32",
   "metadata": {},
   "source": [
    "## üîÑ Recovery Actions (Based on Diagnostic Results)\n",
    "\n",
    "**Choose the appropriate action based on what you found above:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cedcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTION A: If process died - Resume from last checkpoint\n",
    "# This will automatically detect the latest checkpoint and resume training\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "print(\"üîç Searching for latest checkpoint...\")\n",
    "checkpoint_dir = \"/data/Cogumi-LLM/checkpoints\"\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    # Find all checkpoint folders\n",
    "    checkpoints = glob.glob(f\"{checkpoint_dir}/checkpoint-*\")\n",
    "    if checkpoints:\n",
    "        # Sort by step number\n",
    "        checkpoints.sort(key=lambda x: int(x.split('-')[-1]))\n",
    "        latest_checkpoint = checkpoints[-1]\n",
    "        step_num = latest_checkpoint.split('-')[-1]\n",
    "        \n",
    "        print(f\"‚úÖ Found latest checkpoint: {latest_checkpoint}\")\n",
    "        print(f\"   Training was at step {step_num}\")\n",
    "        print(f\"\\n‚ö†Ô∏è To resume training from this checkpoint:\")\n",
    "        print(f\"   1. Modify train.py to add: resume_from_checkpoint='{latest_checkpoint}'\")\n",
    "        print(f\"   2. Re-run the training cell\")\n",
    "        print(f\"\\nI'll create a resume script for you...\")\n",
    "        \n",
    "        # Check how many steps were completed\n",
    "        print(f\"\\nüìä Progress estimate:\")\n",
    "        print(f\"   Completed steps: {step_num}\")\n",
    "        print(f\"   At ~1.7 it/s, you've trained for ~{int(step_num) / 1.7 / 3600:.1f} hours\")\n",
    "    else:\n",
    "        print(\"‚ùå No checkpoints found - training crashed before first checkpoint (step 1000)\")\n",
    "        print(\"   You'll need to restart training from scratch\")\n",
    "else:\n",
    "    print(\"‚ùå Checkpoint directory doesn't exist - training never started properly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b30cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTION B: Create a training script with auto-resume capability\n",
    "# This version will automatically resume from the last checkpoint if it exists\n",
    "\n",
    "import os\n",
    "\n",
    "script_with_resume = \"\"\"# ----------------------------\n",
    "# train.py - H100 Optimized with AUTO-RESUME\n",
    "# Automatically resumes from last checkpoint if training was interrupted\n",
    "# ----------------------------\n",
    "\n",
    "import unsloth\n",
    "import torch\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset\n",
    "from unsloth import FastLanguageModel\n",
    "import gc\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Clear GPU memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Check for existing checkpoints\n",
    "checkpoint_dir = \"/data/Cogumi-LLM/checkpoints\"\n",
    "resume_checkpoint = None\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = glob.glob(f\"{checkpoint_dir}/checkpoint-*\")\n",
    "    if checkpoints:\n",
    "        checkpoints.sort(key=lambda x: int(x.split('-')[-1]))\n",
    "        resume_checkpoint = checkpoints[-1]\n",
    "        print(f\"üîÑ Found checkpoint to resume from: {resume_checkpoint}\")\n",
    "        step_num = resume_checkpoint.split('-')[-1]\n",
    "        print(f\"   Resuming from step {step_num}\")\n",
    "    else:\n",
    "        print(\"üÜï No checkpoints found - starting fresh training\")\n",
    "else:\n",
    "    print(\"üÜï Starting fresh training\")\n",
    "\n",
    "# Load model + tokenizer\n",
    "print(\"üîÑ Loading model...\")\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    max_seq_length=1024,\n",
    "    load_in_4bit=True,\n",
    "    dtype=None,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "print(\"‚úÖ Model loaded\")\n",
    "\n",
    "# Apply LoRA\n",
    "print(\"üîÑ Applying LoRA...\")\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=64,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=3407,\n",
    "    use_rslora=False,\n",
    ")\n",
    "print(\"‚úÖ LoRA applied\")\n",
    "\n",
    "# Prepare for training\n",
    "os.environ[\"UNSLOTH_OFFLOAD_GRADIENTS\"] = \"0\"\n",
    "model = FastLanguageModel.for_training(model)\n",
    "print(\"‚úÖ Model ready\")\n",
    "\n",
    "# Load dataset\n",
    "print(\"üì• Loading dataset...\")\n",
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"/data/Cogumi-LLM/data/phase1/public_500k_filtered.jsonl\",\n",
    "    split=\"train\",\n",
    "    cache_dir=\"/tmp/hf_cache\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "print(f\"‚úÖ Dataset loaded: {len(dataset)} examples\")\n",
    "\n",
    "# Formatting function\n",
    "def formatting_func(examples):\n",
    "    instructions = examples['instruction']\n",
    "    responses = examples['response']\n",
    "    texts = []\n",
    "    for instruction, response in zip(instructions, responses):\n",
    "        text = f\"### Instruction:\\\\\\\\n{instruction}\\\\\\\\n\\\\\\\\n### Response:\\\\\\\\n{response}\"\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "# Training arguments\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"/data/Cogumi-LLM/checkpoints\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,      # Your actual config\n",
    "    gradient_accumulation_steps=2,       # Your actual config\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=10,\n",
    "    logging_steps=1,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=3,\n",
    "    optim=\"adamw_8bit\",\n",
    "    bf16=True,\n",
    "    tf32=True,\n",
    "    dataloader_num_workers=4,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_prefetch_factor=2,\n",
    "    dataloader_persistent_workers=True,\n",
    "    group_by_length=False,\n",
    "    gradient_checkpointing=False,\n",
    "    max_grad_norm=1.0,\n",
    "    logging_first_step=False,\n",
    "    logging_nan_inf_filter=False,\n",
    "    save_safetensors=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "print(\"üîÑ Creating trainer...\")\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    args=args,\n",
    "    formatting_func=formatting_func,\n",
    "    max_seq_length=1024,\n",
    "    packing=False,\n",
    "    dataset_num_proc=2,\n",
    ")\n",
    "print(\"‚úÖ Trainer created\")\n",
    "\n",
    "# Train with auto-resume\n",
    "print(\"=\" * 70)\n",
    "if resume_checkpoint:\n",
    "    print(f\"üîÑ RESUMING training from {resume_checkpoint}\")\n",
    "else:\n",
    "    print(\"üöÄ STARTING fresh training\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    trainer.train(resume_from_checkpoint=resume_checkpoint)\n",
    "    print(\"\\\\n‚úÖ Training completed!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\\\n‚ùå Training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "# Save final model\n",
    "print(\"üíæ Saving model...\")\n",
    "model.save_pretrained(\"/data/Cogumi-LLM/checkpoints/final\")\n",
    "tokenizer.save_pretrained(\"/data/Cogumi-LLM/checkpoints/final\")\n",
    "print(\"‚úÖ Model saved\")\n",
    "\"\"\"\n",
    "\n",
    "# Write the script\n",
    "train_path = \"/data/Cogumi-LLM/train.py\"\n",
    "os.makedirs(os.path.dirname(train_path), exist_ok=True)\n",
    "with open(train_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(script_with_resume)\n",
    "\n",
    "print(f\"‚úÖ Auto-resume training script created at {train_path}\")\n",
    "print(f\"   This script will automatically resume from the last checkpoint if training crashes\")\n",
    "print(f\"\\nüîÑ Now run the training cell again to restart with auto-resume\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1dab5d",
   "metadata": {},
   "source": [
    "## ‚úÖ PERFECT! Resume from Checkpoint 9000\n",
    "\n",
    "**You have checkpoint-9000! That's ~5.3 hours of progress saved!**\n",
    "\n",
    "**Next steps:**\n",
    "1. ‚úÖ Run the cell below (ACTION B) to update train.py with auto-resume\n",
    "2. ‚úÖ Then scroll back up and run the training cell again\n",
    "3. ‚úÖ Training will automatically resume from step 9000\n",
    "\n",
    "**Progress so far:**\n",
    "- Completed: 9,000 / 240,240 steps (~3.7%)\n",
    "- Time invested: ~5.3 hours\n",
    "- Remaining: ~32.7 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676126b8",
   "metadata": {},
   "source": [
    "## üîç Verify Auto-Resume Script Was Created\n",
    "\n",
    "**Before running training, verify the script has resume capability:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a4a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if train.py has auto-resume code\n",
    "import subprocess\n",
    "\n",
    "print(\"üîç Checking if train.py has resume capability...\")\n",
    "result = subprocess.run(['grep', '-n', 'resume_checkpoint', '/data/Cogumi-LLM/train.py'], \n",
    "                       capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úÖ Auto-resume code FOUND in train.py:\")\n",
    "    print(result.stdout)\n",
    "    print(\"\\n‚úÖ Script is ready to auto-resume from checkpoint-9000!\")\n",
    "else:\n",
    "    print(\"‚ùå Auto-resume code NOT found!\")\n",
    "    print(\"‚ö†Ô∏è You need to run the ACTION B cell above first!\")\n",
    "    \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Now check what checkpoint it will find:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check what checkpoint will be detected\n",
    "checkpoint_check = subprocess.run(['ls', '-lht', '/data/Cogumi-LLM/checkpoints/'], \n",
    "                                 capture_output=True, text=True)\n",
    "print(checkpoint_check.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b5865d",
   "metadata": {},
   "source": [
    "## üö® CHECKPOINT CORRUPTED - Use Previous Checkpoint\n",
    "\n",
    "**Checkpoint-9000 is corrupted (incomplete save). We'll use checkpoint-8000 instead.**\n",
    "\n",
    "You still saved **4.7 hours** of work! Better than starting from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9ef7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete corrupted checkpoint-9000 and use checkpoint-8000 instead\n",
    "import subprocess\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "print(\"üóëÔ∏è Removing corrupted checkpoint-9000...\")\n",
    "corrupted_path = \"/data/Cogumi-LLM/checkpoints/checkpoint-9000\"\n",
    "if os.path.exists(corrupted_path):\n",
    "    shutil.rmtree(corrupted_path)\n",
    "    print(f\"‚úÖ Deleted {corrupted_path}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Checkpoint-9000 not found (may already be deleted)\")\n",
    "\n",
    "print(\"\\nüìã Current checkpoints:\")\n",
    "result = subprocess.run(['ls', '-lht', '/data/Cogumi-LLM/checkpoints/'], \n",
    "                       capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "\n",
    "print(\"\\n‚úÖ Now training will resume from checkpoint-8000\")\n",
    "print(\"   Progress: 8,000 steps completed (~4.7 hours saved)\")\n",
    "print(\"   Remaining: ~33.3 hours\")\n",
    "print(\"\\nüîÑ Run the training cell again to resume from checkpoint-8000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de906e5e",
   "metadata": {},
   "source": [
    "## üö® EMERGENCY: Checkpoint Accidentally Deleted\n",
    "\n",
    "**Run this if you accidentally deleted checkpoints with `rm -rf`**\n",
    "\n",
    "This cell will:\n",
    "1. Assess what was lost\n",
    "2. Verify dataset integrity\n",
    "3. Prepare for fresh training restart\n",
    "4. Give you clear next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e8c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EMERGENCY RECOVERY - After Accidental Checkpoint Deletion\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "print(\"üö® CHECKPOINT RECOVERY ASSESSMENT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Check what was deleted\n",
    "checkpoint_dir = \"/data/Cogumi-LLM/checkpoints\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    print(\"\\n‚ùå Checkpoint directory doesn't exist\")\n",
    "    print(\"   All checkpoints were deleted\")\n",
    "else:\n",
    "    remaining = [f for f in os.listdir(checkpoint_dir) if f.startswith(\"checkpoint-\")]\n",
    "    if len(remaining) == 0:\n",
    "        print(\"\\n‚ùå All checkpoints were deleted\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ Found {len(remaining)} remaining checkpoint(s):\")\n",
    "        for cp in remaining:\n",
    "            print(f\"   - {cp}\")\n",
    "\n",
    "# 2. Check dataset integrity\n",
    "dataset_path = \"/data/Cogumi-LLM/data/phase1/public_500k_filtered.jsonl\"\n",
    "if os.path.exists(dataset_path):\n",
    "    size_mb = os.path.getsize(dataset_path) / (1024 * 1024)\n",
    "    print(f\"\\n‚úÖ Dataset intact: {size_mb:.1f} MB\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Dataset not found - needs re-upload\")\n",
    "\n",
    "# 3. Check train.py\n",
    "if os.path.exists(\"/data/Cogumi-LLM/train.py\"):\n",
    "    print(\"\\n‚úÖ train.py exists\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  train.py missing - re-run Step 7 to create it\")\n",
    "\n",
    "# 4. Check disk space\n",
    "result = subprocess.run(['df', '-h', '/data'], capture_output=True, text=True)\n",
    "lines = result.stdout.strip().split('\\n')\n",
    "if len(lines) > 1:\n",
    "    parts = lines[1].split()\n",
    "    print(f\"\\nüíæ Disk Space:\")\n",
    "    print(f\"   Total: {parts[1]}\")\n",
    "    print(f\"   Used: {parts[2]} ({parts[4]})\")\n",
    "    print(f\"   Available: {parts[3]}\")\n",
    "\n",
    "# 5. Recovery recommendation\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìã RECOVERY PLAN:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if not os.path.exists(checkpoint_dir) or len([f for f in os.listdir(checkpoint_dir) if f.startswith(\"checkpoint-\")]) == 0:\n",
    "    print(\"\\nüîÑ OPTION 1: Start Fresh Training (RECOMMENDED)\")\n",
    "    print(\"   - All progress lost, but clean slate\")\n",
    "    print(\"   - Re-run Step 8 (Start Training)\")\n",
    "    print(\"   - Duration: 8-9 hours\")\n",
    "    print(\"   - Cost: ~$10\")\n",
    "    \n",
    "    print(\"\\nüìÇ OPTION 2: Check Vast.ai Backups\")\n",
    "    print(\"   - Some Vast.ai instances auto-backup /data/\")\n",
    "    print(\"   - Check: ls -la /data/.backups/ or similar\")\n",
    "    print(\"   - Contact Vast.ai support if backups exist\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Some checkpoints remain - you can resume!\")\n",
    "    print(\"   - Re-run Step 8 (Start Training)\")\n",
    "    print(\"   - Training will resume from latest checkpoint\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ Assessment complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
